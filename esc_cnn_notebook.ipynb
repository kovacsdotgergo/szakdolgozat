{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/kovacsdotgergo/szakdolgozat.git\n",
    "%cd szakdolgozat\n",
    "!pip install wget torch torchvision torchaudio matplotlib pandas numpy timm==0.4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: tmp for branch\n",
    "!git branch\n",
    "!git checkout feature/cnn\n",
    "!git branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "esc_path, save_path, workspace_path = utils.setup_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "#128x512(436) input mel spect\n",
    "class conv2d_v1(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.conv_layers = nn.Sequential(\n",
    "        nn.Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),#128*512\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2),#64*256\n",
    "        nn.Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),#64*256\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2),#32*128\n",
    "        nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),#32*128\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2),#16*64\n",
    "        nn.Dropout(),\n",
    "\n",
    "        nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),#16*64\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2),#8*32\n",
    "        nn.Dropout(),\n",
    "        nn.Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),#8*32\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2),#4*16\n",
    "        nn.Dropout(),\n",
    "        nn.Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),#4*16\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2)#2*8\n",
    "    )\n",
    "    #flatten all dimensions except batch\n",
    "    self.flatten = nn.Flatten(1)\n",
    "    #fully connected layer\n",
    "    self.mlp = nn.Sequential(\n",
    "        nn.Linear(2*8*512, 1024),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(),\n",
    "        nn.Linear(1024, 50),\n",
    "    )\n",
    "  \n",
    "  def forward(self, x):\n",
    "    #passing through all layers\n",
    "    x = torch.unsqueeze(x, 1)\n",
    "    x = self.conv_layers(x)\n",
    "    x = self.flatten(x)\n",
    "    return self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import esc_dataset\n",
    "import trainer\n",
    "import numpy as np\n",
    "\n",
    "have_cuda = torch.cuda.is_available()\n",
    "\n",
    "## Model\n",
    "audio_model = conv2d_v1()\n",
    "audio_model = torch.nn.DataParallel(audio_model, device_ids=[0])\n",
    "audio_model = audio_model.to(torch.device(\"cuda:0\" if have_cuda else 'cpu'))\n",
    "\n",
    "## Dataset\n",
    "dataset = esc_dataset.ESCdataset(esc_path, n_fft=1024, hop_length=256,\n",
    "                     n_mels=128, augment=False,  log_mel=True,\n",
    "                     use_kaldi=True, target_len=512, resample_rate=22500)\n",
    "\n",
    "#dividing the dataset randomly, 80% train, 10% validation, 10% test\n",
    "numtrain = int(0.8*len(dataset))\n",
    "numval = (len(dataset) - numtrain) // 2\n",
    "numtest = len(dataset) - numtrain - numval\n",
    "split_dataset = torch.utils.data.random_split(dataset, [numtrain, numval, numtest])\n",
    "#using augment on the training data\n",
    "#split_dataset[0].augment = True\n",
    "\n",
    "## DataLoader\n",
    "BATCHSIZE = 16\n",
    "trainloader = torch.utils.data.DataLoader(split_dataset[0], batch_size=BATCHSIZE,\n",
    "                         shuffle=True, num_workers=2)\n",
    "valloader = torch.utils.data.DataLoader(split_dataset[1], batch_size=BATCHSIZE, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(split_dataset[2], batch_size=BATCHSIZE, shuffle=True)\n",
    "\n",
    "## Trainer\n",
    "trainer = trainer.Trainer(audio_model, have_cuda, criterion=nn.CrossEntropyLoss)\n",
    "\n",
    "## Inference\n",
    "spect, label = dataset[0]\n",
    "print(f'trainer inference: {dataset.get_class_name(trainer.inference(spect, ret_index=True).item())}, '\n",
    "    f'true label: {dataset.get_class_name(label)}')\n",
    "\n",
    "## Training\n",
    "lrs = np.logspace(-2, -6, num=5)\n",
    "params = trainer.hyperparameter_plotting(lrs, trainloader, valloader, train_epochs=5)\n",
    "# save_name = 'tmp.pth'\n",
    "# trainer.train(trainloader, valloader, optimizer=torch.optim.AdamW, train_epochs=1,\n",
    "#               val_interval=25, lr=5e-06, save_best_model=True, save_path=save_path + save_name)\n",
    "# trainer.plot_train_proc('30 epoch training')\n",
    "\n",
    "# ## Test\n",
    "# trainer.load_model(save_path + save_name)\n",
    "# print(f'test accuracy: {trainer.test(testloader)}')\n",
    "\n",
    "# ## Inference after training\n",
    "# print(f'Trainer inference after training: {dataset.get_class_name(trainer.inference(spect, ret_index=True).item())}, '\n",
    "#     f'true label: {dataset.get_class_name(label)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c5440d9220ddd61252669e50fcd27d4d057d7cf15fbe79bfa9bf1a741db3cc6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
