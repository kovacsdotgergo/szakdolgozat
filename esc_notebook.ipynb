{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TODO\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kovacsdotgergo/szakdolgozat/blob/feature%2Fcolab_bringup/esc_notebook.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/kovacsdotgergo/szakdolgozat.git\n",
    "%cd szakdolgozat\n",
    "!pip install wget torch torchvision torchaudio matplotlib pandas numpy timm==0.4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in local\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "esc_path, save_path, workspace_path, have_cuda = utils.setup_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import ASTModel\n",
    "import torch\n",
    "## Model\n",
    "INPUT_TDIM = 512\n",
    "audio_model = ASTModel(label_dim=50, input_tdim=INPUT_TDIM, imagenet_pretrain=True, audioset_pretrain=True)\n",
    "audio_model = torch.nn.DataParallel(audio_model, device_ids=[0])\n",
    "audio_model = audio_model.to(torch.device(\"cuda:0\" if have_cuda else 'cpu'))\n",
    "target_len = INPUT_TDIM\n",
    "model_save_path = save_path + '/transformer.pth'\n",
    "train_epochs = 20\n",
    "val_interval = 10\n",
    "train_proc_title = f'Transformer {train_epochs} epoch tanítás'\n",
    "lr = 5e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cnn\n",
    "import torch\n",
    "## Model\n",
    "audio_model = cnn.conv2d_v1()\n",
    "audio_model = torch.nn.DataParallel(audio_model, device_ids=[0])\n",
    "audio_model = audio_model.to(torch.device(\"cuda:0\" if have_cuda else 'cpu'))\n",
    "target_len = 512\n",
    "model_save_path = save_path + '/cnn2d_v1.pth'\n",
    "train_epochs = 80\n",
    "val_interval = 25\n",
    "train_proc_title = f'CNN {train_epochs} epoch tanítás'\n",
    "lr = 0.0009\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lstm\n",
    "import torch\n",
    "INPUT_SIZE = 128\n",
    "HIDDEN_SIZE = 64\n",
    "NUM_LAYERS = 1\n",
    "OUTPUT_SIZE = 50\n",
    "audio_model = lstm.LSTM_mel(INPUT_SIZE, HIDDEN_SIZE, NUM_LAYERS, OUTPUT_SIZE, have_cuda)\n",
    "audio_model = torch.nn.DataParallel(audio_model, device_ids=[0])\n",
    "audio_model = audio_model.to(torch.device(\"cuda:0\" if have_cuda else 'cpu'))\n",
    "target_len = None\n",
    "model_save_path = save_path + '/lstm.pth'\n",
    "train_epochs = 250\n",
    "val_interval = 50\n",
    "train_proc_title = f'LSTM {train_epochs} epoch tanítás'\n",
    "lr = 3e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random split of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import esc_dataset\n",
    "import trainer\n",
    "\n",
    "## Dataset\n",
    "dataset = esc_dataset.ESCdataset(esc_path, n_fft=1024, hop_length=256,\n",
    "                     n_mels=128, augment=False,  log_mel=True,\n",
    "                     use_kaldi=True, target_len=target_len, resample_rate=22500)\n",
    "\n",
    "#dividing the dataset randomly, 80% train, 10% validation, 10% test\n",
    "numtrain = int(0.8*len(dataset))\n",
    "numval = (len(dataset) - numtrain) // 2\n",
    "numtest = len(dataset) - numtrain - numval\n",
    "split_dataset = torch.utils.data.random_split(dataset, [numtrain, numval, numtest])\n",
    "#using augment on the training data\n",
    "#split_dataset[0].augment = True\n",
    "\n",
    "## DataLoader\n",
    "BATCHSIZE = 16\n",
    "trainloader = torch.utils.data.DataLoader(split_dataset[0], batch_size=BATCHSIZE,\n",
    "                         shuffle=True, num_workers=2)\n",
    "valloader = torch.utils.data.DataLoader(split_dataset[1], batch_size=BATCHSIZE, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(split_dataset[2], batch_size=BATCHSIZE, shuffle=True)\n",
    "\n",
    "## Trainer\n",
    "trainer = trainer.Trainer(audio_model, have_cuda, criterion=nn.CrossEntropyLoss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting based on folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import esc_dataset\n",
    "import trainer\n",
    "\n",
    "## Dataset\n",
    "dataset = esc_dataset.ESCdataset(esc_path, fold=[1, 2, 3], n_fft=1024, hop_length=256,\n",
    "                     n_mels=128, augment=False,  log_mel=True,\n",
    "                     use_kaldi=True, target_len=target_len, resample_rate=22500)\n",
    "val_dataset = esc_dataset.ESCdataset(esc_path, fold=4, n_fft=1024, hop_length=256,\n",
    "                     n_mels=128, augment=False,  log_mel=True,\n",
    "                     use_kaldi=True, target_len=target_len, resample_rate=22500)\n",
    "test_dataset = esc_dataset.ESCdataset(esc_path, fold=5, n_fft=1024, hop_length=256,\n",
    "                     n_mels=128, augment=False,  log_mel=True,\n",
    "                     use_kaldi=True, target_len=target_len, resample_rate=22500)\n",
    "\n",
    "## DataLoader\n",
    "BATCHSIZE = 16\n",
    "trainloader = torch.utils.data.DataLoader(dataset, batch_size=BATCHSIZE,\n",
    "                         shuffle=True, num_workers=2)\n",
    "valloader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCHSIZE, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCHSIZE, shuffle=True)\n",
    "\n",
    "## Trainer\n",
    "trainer = trainer.Trainer(audio_model, have_cuda, criterion=nn.CrossEntropyLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inference\n",
    "spect, label = dataset[0]\n",
    "print(f'trainer inference: {dataset.get_class_name(trainer.inference(spect, ret_index=True).item())}, '\n",
    "    f'true label: {dataset.get_class_name(label)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "## Finding a learning rate\n",
    "lrs = np.logspace(-1, -6, num=5)\n",
    "params = trainer.hyperparameter_plotting(lrs, trainloader, valloader, train_epochs=5)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training\n",
    "trainer.train(trainloader, valloader, optimizer=torch.optim.AdamW, train_epochs=train_epochs,\n",
    "              val_interval=val_interval, lr=lr, save_best_model=True, save_path=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test\n",
    "trainer.load_model(model_save_path)\n",
    "print(f'test accuracy: {trainer.test(testloader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualization\n",
    "import random\n",
    "# visualization of the training process\n",
    "visualization.plot_train_proc(trainer.train_stats_logger.get_last_train_stats(), 'Utolso tanítás')\n",
    "# confusion matrix\n",
    "visualization.plot_confusion_matrix(dataset.label_list, 35, testloader, trainer.model, have_cuda)\n",
    "\n",
    "index = random.randint(0, len(dataset))\n",
    "# waveform illustration\n",
    "dataset.log_mel = False\n",
    "visualization.plot_waveform(dataset, index)\n",
    "dataset.log_mel = True\n",
    "# spectogram illustration\n",
    "visualization.plot_spectrogram(dataset, index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c5440d9220ddd61252669e50fcd27d4d057d7cf15fbe79bfa9bf1a741db3cc6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
