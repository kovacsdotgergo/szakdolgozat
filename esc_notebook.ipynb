{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kovacsdotgergo/szakdolgozat/blob/feature%2Fcolab_bringup/esc_notebook.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/kovacsdotgergo/szakdolgozat.git\n",
    "%cd szakdolgozat\n",
    "!pip install wget torch torchvision torchaudio matplotlib pandas numpy timm==0.4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: tmp for branch\n",
    "!git checkout feature/colab_bringup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in local\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "esc_path, save_path, workspace_path = utils.setup_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------AST Model Summary---------------\n",
      "ImageNet pretraining: True, AudioSet pretraining: True\n",
      "frequncey stride=10, time stride=10\n",
      "number of patches=600\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from src.models import ASTModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import esc_dataset\n",
    "import trainer\n",
    "\n",
    "have_cuda = torch.cuda.is_available()\n",
    "\n",
    "input_tdim = 512\n",
    "audio_model = ASTModel(label_dim=50, input_tdim=input_tdim, imagenet_pretrain=True, audioset_pretrain=True)\n",
    "audio_model = torch.nn.DataParallel(audio_model, device_ids=[0])\n",
    "audio_model = audio_model.to(torch.device(\"cuda:0\" if have_cuda else 'cpu'))\n",
    "audio_model.eval()\n",
    "\n",
    "AST_NUM_MEL = 128\n",
    "AST_N_FFT = 1024\n",
    "AST_HOP_LEN = 256\n",
    "BATCHSIZE = 16\n",
    "#instantiating the dataset\n",
    "dataset = esc_dataset.ESCdataset(esc_path, n_fft=AST_N_FFT, hop_length=AST_HOP_LEN,\n",
    "                     n_mels=AST_NUM_MEL, augment=False,  log_mel=True,\n",
    "                     use_kaldi=True, target_len=input_tdim, resample_rate=22500)\n",
    "\n",
    "#dividing the dataset randomly, 80% train, 10% validation, 10% test\n",
    "numtrain = int(0.8*len(dataset))\n",
    "numval = (len(dataset) - numtrain) // 2\n",
    "numtest = len(dataset) - numtrain - numval\n",
    "split_dataset = torch.utils.data.random_split(dataset, [numtrain, numval, numtest])\n",
    "\n",
    "#using augment on the training data\n",
    "#split_dataset[0].augment = True\n",
    "#dataloader instances\n",
    "trainloader = torch.utils.data.DataLoader(split_dataset[0], batch_size=BATCHSIZE,\n",
    "                         shuffle=True, num_workers=2)\n",
    "valloader = torch.utils.data.DataLoader(split_dataset[1], batch_size=BATCHSIZE, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(split_dataset[2], batch_size=BATCHSIZE, shuffle=True)\n",
    "\n",
    "trainer = trainer.Trainer(audio_model, have_cuda, criterion=nn.CrossEntropyLoss)\n",
    "\n",
    "spect, label = dataset[0]\n",
    "print(f'trainer inference: {dataset.label_dict[trainer.inference(spect, ret_index=True).item()]},'\n",
    "    f'true label: {dataset.label_dict[label]}')\n",
    "\n",
    "#lrs = np.logspace(-4, -6, num=10)\n",
    "#params = trainer.hyperparameter_plotting(lrs, trainloader, valloader, train_epochs=5)\n",
    "#print(params)\n",
    "save_name = 'tmp.pth'\n",
    "trainer.train(trainloader, valloader, optimizer=torch.optim.AdamW, train_epochs=3,\n",
    "              val_interval=25, lr=5e-06, save_best_model=True, env_save_path=save_path + save_name\n",
    "             )\n",
    "trainer.plot_train_proc('30 epoch training')\n",
    "print(f'test accuracy: {trainer.test(testloader)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c5440d9220ddd61252669e50fcd27d4d057d7cf15fbe79bfa9bf1a741db3cc6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
