{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kovacsdotgergo/szakdolgozat/blob/master/esc_notebook.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required when running in colab\n",
    "- clones the used repository\n",
    "- changes working directory to the downloaded folder\n",
    "- installs required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/kovacsdotgergo/szakdolgozat.git\n",
    "%cd szakdolgozat\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runs utils.setup_env(), that clones further required repositories and sets\n",
    "working directory and returns required variables decribing the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "esc_path, save_path, workspace_path, have_cuda = utils.setup_env()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning models\n",
    "The following cells instantiate the neural nets and set the variables for the next cells"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Audio Spectorgram Transformer model\n",
    "Source: https://github.com/YuanGongND/ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import ASTModel\n",
    "import torch\n",
    "## Model\n",
    "INPUT_TDIM = 512\n",
    "audio_model = ASTModel(label_dim=50, input_tdim=INPUT_TDIM, imagenet_pretrain=True, audioset_pretrain=True)\n",
    "audio_model = torch.nn.DataParallel(audio_model, device_ids=[0])\n",
    "audio_model = audio_model.to(torch.device(\"cuda:0\" if have_cuda else 'cpu'))\n",
    "\n",
    "target_len = INPUT_TDIM\n",
    "model_save_path = save_path + '/transformer.pth'\n",
    "train_epochs = 20\n",
    "val_interval = 10\n",
    "train_proc_title = f'Transformer {train_epochs} epoch tanítás'\n",
    "lr = 5e-6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2D CNN with Dropout and Maxpool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cnn\n",
    "import torch\n",
    "## Model\n",
    "audio_model = cnn.Conv2d_v1()\n",
    "audio_model = torch.nn.DataParallel(audio_model, device_ids=[0])\n",
    "audio_model = audio_model.to(torch.device(\"cuda:0\" if have_cuda else 'cpu'))\n",
    "\n",
    "target_len = 512\n",
    "model_save_path = save_path + '/cnn2d_v1.pth'\n",
    "train_epochs = 80\n",
    "val_interval = 25\n",
    "train_proc_title = f'CNN {train_epochs} epoch tanítás'\n",
    "lr = 0.0009"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CNN with residual connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cnn\n",
    "import torch\n",
    "## Model\n",
    "version = cnn.Cnn_res_2d.Version_enum.v8\n",
    "audio_model = cnn.Cnn_res_2d(version=version)\n",
    "audio_model = torch.nn.DataParallel(audio_model, device_ids=[0])\n",
    "audio_model = audio_model.to(torch.device(\"cuda:0\" if have_cuda else 'cpu'))\n",
    "\n",
    "target_len = None\n",
    "model_save_path = save_path + f'/cnn_res_2d_{version + 1}.pth'\n",
    "train_epochs = 50\n",
    "val_interval = 49\n",
    "train_proc_title = f'CNN reziduális kapcsolattal, {train_epochs} epoch tanítás'\n",
    "lr = 5e-5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LSTM with one layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lstm\n",
    "import torch\n",
    "## Model\n",
    "audio_model = lstm.LSTM_mel(input_size=50, hidden_size=64, num_layers=1,\n",
    "                            output_size=50, have_cuda=have_cuda)\n",
    "audio_model = torch.nn.DataParallel(audio_model, device_ids=[0])\n",
    "audio_model = audio_model.to(torch.device(\"cuda:0\" if have_cuda else 'cpu'))\n",
    "\n",
    "target_len = None\n",
    "model_save_path = save_path + '/lstm.pth'\n",
    "train_epochs = 250\n",
    "val_interval = 50\n",
    "train_proc_title = f'LSTM {train_epochs} epoch tanítás'\n",
    "lr = 3e-3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiating dataset, dataloader and trainer\n",
    "The options are random split of dataset and split based on folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random split of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import esc_dataset\n",
    "import trainer\n",
    "\n",
    "## Dataset\n",
    "dataset = esc_dataset.ESCdataset(esc_path, n_fft=1024, hop_length=256,\n",
    "                     n_mels=128, augment=False,  log_mel=True,\n",
    "                     use_kaldi=True, target_len=target_len, resample_rate=22500)\n",
    "\n",
    "#dividing the dataset randomly, 80% train, 10% validation, 10% test\n",
    "numtrain = int(0.8*len(dataset))\n",
    "numval = (len(dataset) - numtrain) // 2\n",
    "numtest = len(dataset) - numtrain - numval\n",
    "split_dataset = torch.utils.data.random_split(dataset, [numtrain, numval, numtest])\n",
    "#using augment on the training data\n",
    "#split_dataset[0].augment = True\n",
    "\n",
    "## DataLoader\n",
    "BATCHSIZE = 16\n",
    "trainloader = torch.utils.data.DataLoader(split_dataset[0], batch_size=BATCHSIZE,\n",
    "                         shuffle=True, num_workers=2)\n",
    "valloader = torch.utils.data.DataLoader(split_dataset[1], batch_size=BATCHSIZE, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(split_dataset[2], batch_size=BATCHSIZE, shuffle=True)\n",
    "\n",
    "## Trainer\n",
    "trainer = trainer.Trainer(audio_model, have_cuda, criterion=nn.CrossEntropyLoss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the dataset based on folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import esc_dataset\n",
    "import trainer\n",
    "\n",
    "## Dataset\n",
    "dataset = esc_dataset.ESCdataset(esc_path, folds=[1, 2, 3], n_fft=1024, hop_length=256,\n",
    "                     n_mels=128, augment=False,  log_mel=True,\n",
    "                     use_kaldi=True, target_len=target_len, resample_rate=22500)\n",
    "val_dataset = esc_dataset.ESCdataset(esc_path, folds=4, n_fft=1024, hop_length=256,\n",
    "                     n_mels=128, augment=False,  log_mel=True,\n",
    "                     use_kaldi=True, target_len=target_len, resample_rate=22500)\n",
    "test_dataset = esc_dataset.ESCdataset(esc_path, folds=5, n_fft=1024, hop_length=256,\n",
    "                     n_mels=128, augment=False,  log_mel=True,\n",
    "                     use_kaldi=True, target_len=target_len, resample_rate=22500)\n",
    "\n",
    "## DataLoader\n",
    "BATCHSIZE = 16\n",
    "trainloader = torch.utils.data.DataLoader(dataset, batch_size=BATCHSIZE,\n",
    "                         shuffle=True, num_workers=2)\n",
    "valloader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCHSIZE, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCHSIZE, shuffle=True)\n",
    "\n",
    "## Trainer\n",
    "trainer = trainer.Trainer(audio_model, have_cuda, criterion=nn.CrossEntropyLoss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference about the elements of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inference\n",
    "spect, label = dataset[0]\n",
    "print(f'trainer inference: {dataset.get_class_name(trainer.inference(spect, ret_index=True).item())}, '\n",
    "    f'true label: {dataset.get_class_name(label)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the first few epochs of training using the given learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "## Finding a learning rate\n",
    "lrs = np.logspace(-2, -6, num=5)\n",
    "params = trainer.hyperparameter_plotting(lrs, trainloader, valloader, train_epochs=5)\n",
    "print(params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the network using the trainer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training\n",
    "trainer.train(trainloader, valloader, optimizer=torch.optim.AdamW,\n",
    "              scheduler_milestones=None, scheduler_gamma=1/5, \n",
    "              train_epochs=train_epochs, val_interval=val_interval, lr=lr,\n",
    "              save_best_model=True, save_path=model_save_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading the best model after training and running test on the test fold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test\n",
    "trainer.load_model(model_save_path)\n",
    "print(f'test accuracy: {trainer.test(testloader):.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualizing\n",
    "- Training process of the last training\n",
    "- Confusion matrix calculated on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualization\n",
    "# visualization of the training process\n",
    "visualization.plot_train_proc(trainer.train_stats_logger.get_last_train_stats(), 'Utolso tanítás')\n",
    "# confusion matrix\n",
    "visualization.plot_confusion_matrix(dataset.label_list, 35, testloader, trainer.model, have_cuda)\n",
    "visualization.plot_confusion_matrix(dataset.label_list, 0, testloader, trainer.model, have_cuda)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualizing\n",
    "- waveform of the input\n",
    "- logarithmic mel spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import visualization\n",
    "import random\n",
    "index = random.randint(0, len(dataset))\n",
    "# waveform illustration\n",
    "dataset.log_mel = False\n",
    "visualization.plot_waveform(dataset, index)\n",
    "dataset.log_mel = True\n",
    "# spectogram illustration\n",
    "visualization.plot_spectrogram(dataset, index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c5440d9220ddd61252669e50fcd27d4d057d7cf15fbe79bfa9bf1a741db3cc6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
